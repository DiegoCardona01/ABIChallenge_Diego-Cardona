# ABIChallenge_Diego-Cardona
This repository contains the solution to the MLOps Challenge v7 technical test

# Architecture
The following is the proposed architecture for deploying a model that predicts the earnings of a movie based on various features.
[![architecturemlops-ABin-Bev.png](https://i.postimg.cc/VNkXxmcQ/architecturemlops-ABin-Bev.png)](https://postimg.cc/xXBkHrCt)

# SonarCloud
To track processes, detect errors, and security flaws, SonarCloud has been implemented. Various tests have been run, analyzing different branches of the repository, with a primary focus on the main branch.

SonarCloud Status: [![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=DiegoCardona01_ABIChallenge_Diego-Cardona&metric=alert_status&token=4934187b79ce77a2932ca63d4b86aace4ffe2d3b)](https://sonarcloud.io/summary/new_code?id=DiegoCardona01_ABIChallenge_Diego-Cardona)

## Summary

The project can be generalized as the implementation of workflows in GitHub Actions, maintaining comprehensive CI/CD control over the entire project. This facilitates a secure verification process before accepting pull requests. Additionally, foundational test and continuous training workflows have been added to the deployed API, all seamlessly integrated with SonarCloud, as demonstrated in the previous section. There's even a SonarCloud badge to indicate whether the branch is approved and secure according to SonarCloud.

## Deployed ML Model

The deployed model comes with a Dockerfile where the configuration for creating the Docker image has been set up. This allows running the API locally, created with FastAPI.

To use the deployed inference model, access the following link:
[Inference Model Link](https://deployment-abichallenge-ml-service-ejp2ragddq-uc.a.run.app)

Additionally, if you wish to use it as an inference endpoint, you can directly access the prediction section with the following link:
[Prediction Endpoint Link](https://deployment-abichallenge-ml-service-ejp2ragddq-uc.a.run.app/v1/predict/)

A folder named 'endpoint_usagetest' has also been added, containing an example of how to use the deployed model as an inference endpoint.

## Google Cloud Platform (GCP)

Furthermore, Google Cloud's cloud service has been utilized. Here, data for training the model and data generated by our deployed API are stored, functioning as the DataLake for the project.

Our Docker image has also been registered with the Google Run service for management and on-demand access.

## CI/CD and CML

All these steps have been scheduled and prepared for continuous execution. Our CI/CD file is parameterized to run every 15 hours. Significantly, the main branch holds the utmost importance, where each pull request involves retraining the model (either manually triggered). Both testing and SonarCloud test activation have been configured to trigger on every push or pull request, ensuring heightened security for our project.
